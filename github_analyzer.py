#!/usr/bin/env python3
"""
GitHub Portfolio Analyzer for Claude Code
ç„¡æ–™ã§GitHubãƒªãƒã‚¸ãƒˆãƒªã‚’åˆ†æã—ã€æŠ€è¡“çš„å‚¾å‘ã¨ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—ã‚’å¯è¦–åŒ–
"""

import requests
import json
import os
import sys
from datetime import datetime, timedelta
from collections import Counter, defaultdict
import argparse
from typing import Dict, List, Any, Optional
import re

# .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
def load_env_file(env_path: str = '.env'):
    """Load environment variables from .env file"""
    if os.path.exists(env_path):
        with open(env_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()


class GitHubAnalyzer:
    def __init__(self, token: str):
        self.token = token
        self.headers = {
            'Authorization': f'token {token}',
            'Accept': 'application/vnd.github.v3+json'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        
    def get_user_info(self) -> Dict[str, Any]:
        """èªè¨¼ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—"""
        response = self.session.get('https://api.github.com/user')
        response.raise_for_status()
        return response.json()
    
    def get_all_repositories(self, max_repos: int = 500) -> List[Dict[str, Any]]:
        """å…¨ãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰"""
        repos = []
        page = 1
        per_page = 100
        
        print(f"ğŸ“¦ ãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—ä¸­...")
        
        while len(repos) < max_repos:
            params = {
                'type': 'all',
                'sort': 'updated',
                'per_page': per_page,
                'page': page
            }
            
            response = self.session.get('https://api.github.com/user/repos', params=params)
            response.raise_for_status()
            
            page_repos = response.json()
            if not page_repos:
                break
                
            repos.extend(page_repos[:max_repos - len(repos)])
            print(f"  ğŸ“‹ {len(repos)} å€‹ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—æ¸ˆã¿")
            page += 1
            
        return repos
    
    def get_repository_languages(self, owner: str, repo: str) -> Dict[str, int]:
        """ãƒªãƒã‚¸ãƒˆãƒªã®è¨€èªçµ±è¨ˆã‚’å–å¾—"""
        try:
            response = self.session.get(f'https://api.github.com/repos/{owner}/{repo}/languages')
            response.raise_for_status()
            return response.json()
        except:
            return {}
    
    def get_repository_contents(self, owner: str, repo: str, path: str = '') -> List[Dict[str, Any]]:
        """ãƒªãƒã‚¸ãƒˆãƒªã®å†…å®¹ã‚’å–å¾—"""
        try:
            response = self.session.get(f'https://api.github.com/repos/{owner}/{repo}/contents/{path}')
            response.raise_for_status()
            return response.json()
        except:
            return []
    
    def get_file_content(self, owner: str, repo: str, path: str) -> Optional[str]:
        """ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ã‚’å–å¾—"""
        try:
            response = self.session.get(f'https://api.github.com/repos/{owner}/{repo}/contents/{path}')
            response.raise_for_status()
            file_data = response.json()
            
            if file_data.get('type') == 'file' and file_data.get('size', 0) < 50000:  # 50KBåˆ¶é™
                import base64
                content = base64.b64decode(file_data['content']).decode('utf-8', errors='ignore')
                return content[:10000]  # æœ€å¤§10000æ–‡å­—
        except:
            pass
        return None
    
    def analyze_repository_tech_stack(self, repo: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒªãƒã‚¸ãƒˆãƒªã®æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã‚’åˆ†æ"""
        try:
            owner = repo['owner']['login']
            name = repo['name']
            
            # åŸºæœ¬æƒ…å ±
            analysis = {
                'name': name,
                'description': repo.get('description', '') or '',
                'primary_language': repo.get('language') or 'Unknown',
                'size': repo.get('size', 0),
                'stars': repo.get('stargazers_count', 0),
                'forks': repo.get('forks_count', 0),
                'created_at': repo.get('created_at', ''),
                'updated_at': repo.get('updated_at', ''),
                'topics': repo.get('topics', []) or [],
                'languages': {},
                'frameworks': [],
                'tools': [],
                'complexity': 'low',
                'category': 'other'
            }
            
            # è¨€èªçµ±è¨ˆå–å¾—
            languages = self.get_repository_languages(owner, name)
            analysis['languages'] = languages
            
            # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ
            important_files = [
                'package.json', 'requirements.txt', 'go.mod', 'Cargo.toml',
                'pom.xml', 'build.gradle', 'composer.json', 'Gemfile',
                'README.md', 'docker-compose.yml', 'Dockerfile'
            ]
            
            for file_name in important_files:
                content = self.get_file_content(owner, name, file_name)
                if content:
                    analysis = self._analyze_file_content(analysis, file_name, content)
            
            # è¤‡é›‘åº¦ã¨ã‚«ãƒ†ã‚´ãƒªã®æ¨å®š
            analysis = self._estimate_complexity_and_category(analysis)
            
            return analysis
        
        except Exception as e:
            print(f"    âš ï¸  {name} ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
            return {
                'name': name,
                'description': '',
                'primary_language': 'Unknown',
                'size': 0,
                'stars': 0,
                'forks': 0,
                'created_at': '',
                'updated_at': '',
                'topics': [],
                'languages': {},
                'frameworks': [],
                'tools': [],
                'complexity': 'low',
                'category': 'other'
            }
    
    def _analyze_file_content(self, analysis: Dict[str, Any], filename: str, content: str) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‹ã‚‰æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã‚’æ¨å®š"""
        
        if filename == 'package.json':
            try:
                pkg_data = json.loads(content)
                deps = list(pkg_data.get('dependencies', {}).keys())
                dev_deps = list(pkg_data.get('devDependencies', {}).keys())
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ¤œå‡º
                frameworks = []
                if any(dep in deps for dep in ['react', '@types/react']):
                    frameworks.append('React')
                if any(dep in deps for dep in ['vue', 'nuxt']):
                    frameworks.append('Vue.js')
                if any(dep in deps for dep in ['angular', '@angular/core']):
                    frameworks.append('Angular')
                if any(dep in deps for dep in ['express', 'koa', 'fastify']):
                    frameworks.append('Node.js Backend')
                if any(dep in deps for dep in ['next', 'gatsby']):
                    frameworks.append('Static Site Generator')
                
                analysis['frameworks'].extend(frameworks)
                analysis['tools'].extend(['npm/yarn'])
                
            except json.JSONDecodeError:
                pass
        
        elif filename == 'requirements.txt':
            lines = content.strip().split('\n')
            frameworks = []
            
            for line in lines:
                package = line.split('==')[0].split('>=')[0].split('~=')[0].strip()
                if package in ['django', 'Django']:
                    frameworks.append('Django')
                elif package in ['flask', 'Flask']:
                    frameworks.append('Flask')
                elif package in ['fastapi', 'FastAPI']:
                    frameworks.append('FastAPI')
                elif package in ['streamlit']:
                    frameworks.append('Streamlit')
                elif package in ['pandas', 'numpy', 'scipy']:
                    frameworks.append('Data Science')
                elif package in ['tensorflow', 'torch', 'pytorch']:
                    frameworks.append('Machine Learning')
            
            analysis['frameworks'].extend(frameworks)
            analysis['tools'].extend(['pip'])
        
        elif filename in ['go.mod']:
            if 'gin-gonic/gin' in content:
                analysis['frameworks'].append('Gin (Go)')
            if 'gorilla/mux' in content:
                analysis['frameworks'].append('Gorilla Mux')
            analysis['tools'].append('Go Modules')
        
        elif filename == 'Cargo.toml':
            if 'actix-web' in content:
                analysis['frameworks'].append('Actix Web')
            if 'rocket' in content:
                analysis['frameworks'].append('Rocket')
            analysis['tools'].append('Cargo')
        
        elif filename == 'Dockerfile':
            analysis['tools'].append('Docker')
        
        elif filename == 'docker-compose.yml':
            analysis['tools'].append('Docker Compose')
        
        return analysis
    
    def _estimate_complexity_and_category(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """è¤‡é›‘åº¦ã¨ã‚«ãƒ†ã‚´ãƒªã‚’æ¨å®š"""
        
        # è¤‡é›‘åº¦æ¨å®š
        complexity_score = 0
        
        # è¨€èªæ•°
        lang_count = len(analysis['languages'])
        complexity_score += min(lang_count * 10, 30)
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ•°
        framework_count = len(analysis['frameworks'])
        complexity_score += min(framework_count * 15, 45)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        size = analysis['size']
        if size > 10000:
            complexity_score += 30
        elif size > 1000:
            complexity_score += 15
        
        # ã‚¹ã‚¿ãƒ¼æ•°ï¼ˆäººæ°—åº¦ï¼‰
        stars = analysis['stars']
        if stars > 100:
            complexity_score += 20
        elif stars > 10:
            complexity_score += 10
        
        if complexity_score >= 60:
            analysis['complexity'] = 'high'
        elif complexity_score >= 30:
            analysis['complexity'] = 'medium'
        else:
            analysis['complexity'] = 'low'
        
        # ã‚«ãƒ†ã‚´ãƒªæ¨å®š
        primary_lang = (analysis['primary_language'] or '').lower()
        frameworks = [f.lower() for f in analysis['frameworks']]
        
        if any(f in frameworks for f in ['react', 'vue.js', 'angular', 'static site generator']):
            analysis['category'] = 'frontend'
        elif any(f in frameworks for f in ['django', 'flask', 'fastapi', 'node.js backend', 'gin (go)', 'actix web']):
            analysis['category'] = 'backend'
        elif any(f in frameworks for f in ['data science', 'machine learning']):
            analysis['category'] = 'data/ml'
        elif 'docker' in analysis['tools']:
            analysis['category'] = 'devops'
        elif primary_lang in ['javascript', 'typescript', 'html', 'css']:
            analysis['category'] = 'frontend'
        elif primary_lang in ['python', 'java', 'go', 'rust', 'c++']:
            analysis['category'] = 'backend'
        else:
            analysis['category'] = 'other'
        
        return analysis
    
    def generate_portfolio_report(self, analyses: List[Dict[str, Any]]) -> str:
        """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        
        # çµ±è¨ˆè¨ˆç®—
        total_repos = len(analyses)
        languages = Counter()
        frameworks = Counter()
        categories = Counter()
        complexities = Counter()
        
        total_stars = 0
        total_forks = 0
        
        for analysis in analyses:
            # è¨€èªçµ±è¨ˆï¼ˆãƒã‚¤ãƒˆæ•°åŠ é‡ï¼‰
            for lang, bytes_count in analysis['languages'].items():
                languages[lang] += bytes_count
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯çµ±è¨ˆ
            for framework in analysis['frameworks']:
                frameworks[framework] += 1
            
            # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆ
            categories[analysis['category']] += 1
            
            # è¤‡é›‘åº¦çµ±è¨ˆ
            complexities[analysis['complexity']] += 1
            
            # ã‚¹ã‚¿ãƒ¼ãƒ»ãƒ•ã‚©ãƒ¼ã‚¯æ•°
            total_stars += analysis['stars']
            total_forks += analysis['forks']
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = f"""
# ğŸš€ GitHub Portfolio Analysis Report
ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š Portfolio Overview
- **ç·ãƒªãƒã‚¸ãƒˆãƒªæ•°**: {total_repos}
- **ç·ã‚¹ã‚¿ãƒ¼æ•°**: {total_stars}
- **ç·ãƒ•ã‚©ãƒ¼ã‚¯æ•°**: {total_forks}
- **å¹³å‡ã‚¹ã‚¿ãƒ¼æ•°**: {total_stars/max(total_repos, 1):.1f}

## ğŸ’» æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯åˆ†æ

### ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª (ä¸Šä½10ä½)
"""
        
        # è¨€èªãƒ©ãƒ³ã‚­ãƒ³ã‚°
        top_languages = languages.most_common(10)
        total_bytes = sum(languages.values())
        
        for i, (lang, bytes_count) in enumerate(top_languages, 1):
            percentage = (bytes_count / max(total_bytes, 1)) * 100
            report += f"{i:2d}. **{lang}**: {percentage:.1f}% ({bytes_count:,} bytes)\n"
        
        report += "\n### ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒª (ä¸Šä½10ä½)\n"
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        top_frameworks = frameworks.most_common(10)
        for i, (framework, count) in enumerate(top_frameworks, 1):
            percentage = (count / max(total_repos, 1)) * 100
            report += f"{i:2d}. **{framework}**: {count} projects ({percentage:.1f}%)\n"
        
        report += f"""
## ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æ

### ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†å¸ƒ
"""
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ
        for category, count in categories.most_common():
            percentage = (count / max(total_repos, 1)) * 100
            report += f"- **{category.title()}**: {count} projects ({percentage:.1f}%)\n"
        
        report += "\n### è¤‡é›‘åº¦åˆ†å¸ƒ\n"
        
        # è¤‡é›‘åº¦åˆ†å¸ƒ
        for complexity, count in complexities.most_common():
            percentage = (count / max(total_repos, 1)) * 100
            report += f"- **{complexity.title()}**: {count} projects ({percentage:.1f}%)\n"
        
        # æ¨å¥¨äº‹é …
        report += self._generate_recommendations(analyses, languages, frameworks, categories)
        
        return report
    
    def _generate_recommendations(self, analyses: List[Dict[str, Any]], 
                                languages: Counter, frameworks: Counter, 
                                categories: Counter) -> str:
        """æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
        
        recommendations = "\n## ğŸ¯ æ¨å¥¨äº‹é …\n\n"
        
        # æŠ€è¡“çš„å¤šæ§˜æ€§ã®åˆ†æ
        lang_diversity = len(languages)
        framework_diversity = len(frameworks)
        
        recommendations += "### æŠ€è¡“ã‚¹ã‚­ãƒ«å‘ä¸Š\n"
        
        # è¨€èªã®æ¨å¥¨
        top_lang = languages.most_common(1)[0][0] if languages else "Unknown"
        
        if lang_diversity < 3:
            recommendations += f"- ç¾åœ¨ã®ãƒ¡ã‚¤ãƒ³è¨€èªã¯ **{top_lang}** ã§ã™ã€‚æŠ€è¡“çš„å¤šæ§˜æ€§å‘ä¸Šã®ãŸã‚ã€ä»¥ä¸‹ã®è¨€èªå­¦ç¿’ã‚’æ¨å¥¨:\n"
            suggestions = []
            if 'Python' not in languages:
                suggestions.append("Pythonï¼ˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼‰")
            if 'JavaScript' not in languages and 'TypeScript' not in languages:
                suggestions.append("JavaScript/TypeScriptï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ»ãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯ï¼‰")
            if 'Go' not in languages:
                suggestions.append("Goï¼ˆé«˜æ€§èƒ½ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼‰")
            
            for suggestion in suggestions[:2]:  # æœ€å¤§2ã¤ã¾ã§
                recommendations += f"  - {suggestion}\n"
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æ¨å¥¨
        if framework_diversity < 5:
            recommendations += "- ãƒ¢ãƒ€ãƒ³ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å­¦ç¿’ã‚’æ¨å¥¨:\n"
            
            frontend_frameworks = [f for f in frameworks if f in ['React', 'Vue.js', 'Angular']]
            if not frontend_frameworks:
                recommendations += "  - **React** ã¾ãŸã¯ **Vue.js** (ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰é–‹ç™º)\n"
            
            backend_frameworks = [f for f in frameworks if f in ['Django', 'Flask', 'FastAPI', 'Express']]
            if not backend_frameworks:
                recommendations += "  - **FastAPI** ã¾ãŸã¯ **Express** (ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰APIé–‹ç™º)\n"
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—ã®æ¨å¥¨
        recommendations += "\n### ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå¼·åŒ–\n"
        
        if categories['frontend'] == 0:
            recommendations += "- **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹é–‹ç™ºã‚¹ã‚­ãƒ«ã®è¨¼æ˜\n"
        
        if categories['backend'] == 0:
            recommendations += "- **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ»API**: ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰é–‹ç™ºã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã‚¹ã‚­ãƒ«ã®è¨¼æ˜\n"
        
        if categories['data/ml'] == 0:
            recommendations += "- **ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»æ©Ÿæ¢°å­¦ç¿’**: ç¾ä»£çš„ãªãƒ‡ãƒ¼ã‚¿æ´»ç”¨ã‚¹ã‚­ãƒ«ã®è¨¼æ˜\n"
        
        if categories['devops'] < 2:
            recommendations += "- **DevOpsãƒ»ã‚¤ãƒ³ãƒ•ãƒ©**: Dockerã€CI/CDã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚¹ã‚­ãƒ«ã®è¨¼æ˜\n"
        
        # å“è³ªå‘ä¸Šã®æ¨å¥¨
        recommendations += "\n### ã‚³ãƒ¼ãƒ‰å“è³ªå‘ä¸Š\n"
        
        low_star_repos = len([a for a in analyses if a['stars'] == 0])
        if low_star_repos > len(analyses) * 0.8:
            recommendations += "- **READMEæ”¹å–„**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç›®çš„ãƒ»ä½¿ç”¨æ–¹æ³•ãƒ»æŠ€è¡“é¸æŠç†ç”±ã‚’æ˜ç¢ºã«è¨˜è¼‰\n"
            recommendations += "- **ãƒ‡ãƒ¢ãƒ»ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ**: å®Ÿéš›ã®å‹•ä½œã‚’è¦–è¦šçš„ã«ç¤ºã™\n"
        
        recommendations += "- **ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰**: å“è³ªä¿è¨¼ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒªã‚ºãƒ ã®è¨¼æ˜\n"
        recommendations += "- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: APIä»•æ§˜æ›¸ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³ãªã©ã®æŠ€è¡“æ–‡æ›¸\n"
        
        return recommendations
    
    def save_detailed_analysis(self, analyses: List[Dict[str, Any]], filename: str = 'portfolio_analysis.json'):
        """è©³ç´°åˆ†æçµæœã‚’JSONã§ä¿å­˜"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(analyses, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ è©³ç´°åˆ†æçµæœã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    def generate_claude_analysis_prompt(self, analyses: List[Dict[str, Any]], user_info: Dict[str, Any]) -> str:
        """Claude Codeç”¨ã®è©³ç´°åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
        
        # çµ±è¨ˆè¨ˆç®—
        total_repos = len(analyses)
        languages = Counter()
        frameworks = Counter()
        categories = Counter()
        tools = Counter()
        
        recent_projects = []
        complex_projects = []
        popular_projects = []
        
        for analysis in analyses:
            # è¨€èªçµ±è¨ˆ
            for lang, bytes_count in analysis['languages'].items():
                languages[lang] += bytes_count
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ»ãƒ„ãƒ¼ãƒ«çµ±è¨ˆ
            for framework in analysis['frameworks']:
                frameworks[framework] += 1
            for tool in analysis['tools']:
                tools[tool] += 1
            
            # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆ
            categories[analysis['category']] += 1
            
            # æ³¨ç›®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†é¡
            if analysis['updated_at']:
                try:
                    updated = datetime.fromisoformat(analysis['updated_at'].replace('Z', '+00:00'))
                    if updated > datetime.now().replace(tzinfo=updated.tzinfo) - timedelta(days=180):
                        recent_projects.append(analysis)
                except:
                    pass
            
            if analysis['complexity'] == 'high':
                complex_projects.append(analysis)
            
            if analysis['stars'] > 0:
                popular_projects.append(analysis)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        prompt = f"""# GitHub Portfolio æ·±å±¤åˆ†æä¾é ¼

ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ†ãƒƒã‚¯ãƒªãƒ¼ãƒ‰ã‹ã¤ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®GitHubãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ‡ãƒ¼ã‚¿ã‚’è©³ç´°ã«åˆ†æã—ã€æŠ€è¡“çš„è©•ä¾¡ã¨ã‚­ãƒ£ãƒªã‚¢æˆ¦ç•¥ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

## ğŸ“Š åŸºæœ¬æƒ…å ±
- **GitHub ãƒ¦ãƒ¼ã‚¶ãƒ¼å**: {user_info.get('login', 'N/A')}
- **å…¬é–‹ãƒªãƒã‚¸ãƒˆãƒªæ•°**: {user_info.get('public_repos', 'N/A')}
- **ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°**: {user_info.get('followers', 'N/A')}
- **åˆ†æå¯¾è±¡ãƒªãƒã‚¸ãƒˆãƒª**: {total_repos}

## ğŸ’» æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯è©³ç´°

### ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªåˆ†å¸ƒ
```json
{json.dumps(dict(languages.most_common()), ensure_ascii=False, indent=2)}
```

### ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨çŠ¶æ³
```json
{json.dumps(dict(frameworks.most_common()), ensure_ascii=False, indent=2)}
```

### é–‹ç™ºãƒ„ãƒ¼ãƒ«ãƒ»æŠ€è¡“
```json
{json.dumps(dict(tools.most_common()), ensure_ascii=False, indent=2)}
```

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ
```json
{json.dumps(dict(categories.most_common()), ensure_ascii=False, indent=2)}
```

## ğŸ¯ æ³¨ç›®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

### æœ€è¿‘ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ (éå»6ãƒ¶æœˆ)
```json
{json.dumps([{
    'name': p['name'],
    'primary_language': p['primary_language'],
    'frameworks': p['frameworks'],
    'complexity': p['complexity'],
    'description': p['description'][:100] + '...' if len(p['description']) > 100 else p['description']
} for p in recent_projects[:5]], ensure_ascii=False, indent=2)}
```

### é«˜è¤‡é›‘åº¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
```json
{json.dumps([{
    'name': p['name'],
    'primary_language': p['primary_language'],
    'frameworks': p['frameworks'],
    'tools': p['tools'],
    'languages_count': len(p['languages']),
    'description': p['description'][:100] + '...' if len(p['description']) > 100 else p['description']
} for p in complex_projects[:5]], ensure_ascii=False, indent=2)}
```

### äººæ°—ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ (ã‚¹ã‚¿ãƒ¼ç²å¾—)
```json
{json.dumps([{
    'name': p['name'],
    'stars': p['stars'],
    'forks': p['forks'],
    'primary_language': p['primary_language'],
    'frameworks': p['frameworks'],
    'description': p['description'][:100] + '...' if len(p['description']) > 100 else p['description']
} for p in popular_projects[:5]], ensure_ascii=False, indent=2)}
```

## ğŸ“‹ åˆ†æä¾é ¼å†…å®¹

ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è©³ç´°ã«åˆ†æãƒ»è©•ä¾¡ã—ã¦ãã ã•ã„ï¼š

### 1. æŠ€è¡“çš„ã‚¹ã‚­ãƒ«è©•ä¾¡ (å„é …ç›®10ç‚¹æº€ç‚¹)
- **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰æŠ€è¡“åŠ›**
- **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æŠ€è¡“åŠ›**
- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ»ãƒ‡ãƒ¼ã‚¿å‡¦ç†**
- **DevOpsãƒ»ã‚¤ãƒ³ãƒ•ãƒ©**
- **ãƒ¢ãƒã‚¤ãƒ«é–‹ç™º**
- **AI/MLæŠ€è¡“**
- **æŠ€è¡“ã®å¤šæ§˜æ€§ã¨æ·±åº¦**
- **ãƒ¢ãƒ€ãƒ³ãªæŠ€è¡“ã¸ã®é©å¿œ**

### 2. ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å“è³ªè©•ä¾¡
- **ã‚³ãƒ¼ãƒ‰è¨­è¨ˆãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆãƒ»ç®¡ç†**
- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»READMEå“è³ª**
- **ãƒ†ã‚¹ãƒˆãƒ»å“è³ªä¿è¨¼ã¸ã®å–ã‚Šçµ„ã¿**
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ„è­˜**
- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**

### 3. ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒ»ãƒ“ã‚¸ãƒã‚¹è¦–ç‚¹
- **å®Ÿç”¨æ€§ãƒ»å¸‚å ´ä¾¡å€¤**
- **UI/UXè¨­è¨ˆåŠ›**
- **å•é¡Œè§£æ±ºã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**
- **ç¶™ç¶šçš„ãªé–‹ç™ºãƒ»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹**
- **ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹è²¢çŒ®**

### 4. ã‚­ãƒ£ãƒªã‚¢æˆ¦ç•¥ææ¡ˆ
- **ç¾åœ¨ã®å¸‚å ´ä¾¡å€¤(å¹´åãƒ¬ãƒ³ã‚¸äºˆæƒ³)**
- **å¼·ã¿ã¨å¼±ã¿ã®æ˜ç¢ºåŒ–**
- **æ¬¡ã«ç¿’å¾—ã™ã¹ãæŠ€è¡“(å„ªå…ˆåº¦é †)**
- **ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ”¹å–„é …ç›®(å…·ä½“çš„)**
- **è»¢è·ãƒ»ã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒƒãƒ—æˆ¦ç•¥**
- **å­¦ç¿’è¨ˆç”»(6ãƒ¶æœˆãƒ»1å¹´ãƒ»3å¹´)**

### 5. å…·ä½“çš„æ”¹å–„ææ¡ˆ
- **ä¸è¶³ã—ã¦ã„ã‚‹æŠ€è¡“é ˜åŸŸ**
- **ä½œã‚‹ã¹ããƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ(3-5å€‹)**
- **æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ”¹å–„ç‚¹**
- **æŠ€è¡“ãƒ–ãƒ­ã‚°ãƒ»ç™ºä¿¡ã™ã¹ãå†…å®¹**
- **å‚åŠ ã™ã¹ãã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆ**

## ğŸ“ å‡ºåŠ›å½¢å¼
- å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯è©³ç´°ã‹ã¤å…·ä½“çš„ã«
- ã‚¹ã‚³ã‚¢ã¯æ ¹æ‹ ã¨ã¨ã‚‚ã«æç¤º
- æ”¹å–„ææ¡ˆã¯å®Ÿè¡Œå¯èƒ½ãªå…·ä½“æ¡ˆã‚’
- å¸‚å ´å‹•å‘ã¨ç…§ã‚‰ã—åˆã‚ã›ãŸåˆ†æã‚’
- ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®ãƒ¬ãƒ™ãƒ«æ„Ÿã‚’è€ƒæ…®ã—ãŸç¾å®Ÿçš„ãªææ¡ˆã‚’

ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ï¼"""

        return prompt


def main():
    parser = argparse.ArgumentParser(description='GitHub Portfolio Analyzer')
    parser.add_argument('--token', help='GitHub Personal Access Token')
    parser.add_argument('--max-repos', type=int, default=100, help='åˆ†æã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒªã®æœ€å¤§æ•°')
    parser.add_argument('--output', default='report.md', help='ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å')
    parser.add_argument('--save-json', action='store_true', help='è©³ç´°åˆ†æçµæœã‚’JSONã§ä¿å­˜')
    
    args = parser.parse_args()
    
    # .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    load_env_file()
    
    # GitHub Tokenå–å¾—
    token = args.token or os.getenv('GITHUB_TOKEN')
    if not token:
        print("âŒ GitHub Personal Access TokenãŒå¿…è¦ã§ã™")
        print("   --token ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¾ãŸã¯ GITHUB_TOKEN ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        sys.exit(1)
    
    try:
        analyzer = GitHubAnalyzer(token)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å–å¾—
        user_info = analyzer.get_user_info()
        print(f"ğŸ” {user_info['login']} ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’åˆ†æä¸­...")
        
        # ãƒªãƒã‚¸ãƒˆãƒªå–å¾—
        repos = analyzer.get_all_repositories(args.max_repos)
        print(f"ğŸ“¦ {len(repos)} å€‹ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—ã—ã¾ã—ãŸ")
        
        # å„ãƒªãƒã‚¸ãƒˆãƒªã‚’åˆ†æ
        analyses = []
        for i, repo in enumerate(repos, 1):
            print(f"ğŸ” [{i:3d}/{len(repos):3d}] {repo['name']} ã‚’åˆ†æä¸­...")
            analysis = analyzer.analyze_repository_tech_stack(repo)
            analyses.append(analysis)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print("ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
        report = analyzer.generate_portfolio_report(analyses)
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ… åˆ†æå®Œäº†ï¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ {args.output} ã«ä¿å­˜ã—ã¾ã—ãŸ")
        
        # è©³ç´°åˆ†æçµæœã‚’JSONã§ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if args.save_json:
            analyzer.save_detailed_analysis(analyses)
        
        # Claude Codeç”¨ã®è©³ç´°åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
        claude_prompt = analyzer.generate_claude_analysis_prompt(analyses, user_info)
        claude_prompt_file = 'claude_analysis_prompt.md'
        with open(claude_prompt_file, 'w', encoding='utf-8') as f:
            f.write(claude_prompt)
        
        print(f"ğŸ¤– Claude Codeåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ {claude_prompt_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")
        print("\n" + "="*80)
        print("ğŸ“‹ æ¬¡ã®æ‰‹é †:")
        print("1. Claude Codeã§ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
        print("2. è©³ç´°ãªæŠ€è¡“åˆ†æã¨ã‚­ãƒ£ãƒªã‚¢ææ¡ˆã‚’å—ã‘å–ã‚Œã¾ã™")
        print("="*80)
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ GitHub API ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()