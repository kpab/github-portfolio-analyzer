#!/usr/bin/env python3
"""
GitHub Portfolio Analyzer for Claude Code
ç„¡æ–™ã§GitHubãƒªãƒã‚¸ãƒˆãƒªã‚’åˆ†æã—ã€æŠ€è¡“çš„å‚¾å‘ã¨ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—ã‚’å¯è¦–åŒ–
"""

import requests
import json
import os
import sys
from datetime import datetime, timedelta
from collections import Counter, defaultdict
import argparse
from typing import Dict, List, Any, Optional
import re

# .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
def load_env_file(env_path: str = '.env'):
    """Load environment variables from .env file"""
    if os.path.exists(env_path):
        with open(env_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()


class GitHubAnalyzer:
    def __init__(self, token: str):
        self.token = token
        self.headers = {
            'Authorization': f'token {token}',
            'Accept': 'application/vnd.github.v3+json'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        
    def get_user_info(self) -> Dict[str, Any]:
        """èªè¨¼ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—"""
        response = self.session.get('https://api.github.com/user')
        response.raise_for_status()
        return response.json()
    
    def get_all_repositories(self, max_repos: int = 500) -> List[Dict[str, Any]]:
        """å…¨ãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰"""
        repos = []
        page = 1
        per_page = 100
        
        print(f"ğŸ“¦ ãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—ä¸­...")
        
        while len(repos) < max_repos:
            params = {
                'type': 'all',
                'sort': 'updated',
                'per_page': per_page,
                'page': page
            }
            
            response = self.session.get('https://api.github.com/user/repos', params=params)
            response.raise_for_status()
            
            page_repos = response.json()
            if not page_repos:
                break
                
            repos.extend(page_repos[:max_repos - len(repos)])
            print(f"  ğŸ“‹ {len(repos)} å€‹ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—æ¸ˆã¿")
            page += 1
            
        return repos
    
    def get_repository_languages(self, owner: str, repo: str) -> Dict[str, int]:
        """ãƒªãƒã‚¸ãƒˆãƒªã®è¨€èªçµ±è¨ˆã‚’å–å¾—"""
        try:
            response = self.session.get(f'https://api.github.com/repos/{owner}/{repo}/languages')
            response.raise_for_status()
            return response.json()
        except:
            return {}
    
    def get_repository_contents(self, owner: str, repo: str, path: str = '') -> List[Dict[str, Any]]:
        """ãƒªãƒã‚¸ãƒˆãƒªã®å†…å®¹ã‚’å–å¾—"""
        try:
            response = self.session.get(f'https://api.github.com/repos/{owner}/{repo}/contents/{path}')
            response.raise_for_status()
            return response.json()
        except:
            return []
    
    def get_repository_stats(self, owner: str, repo: str) -> Dict[str, Any]:
        """ãƒªãƒã‚¸ãƒˆãƒªã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ï¼ˆã‚³ãƒŸãƒƒãƒˆæ•°ã€ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼æ•°ãªã©ï¼‰"""
        stats = {
            'commit_count': 0,
            'contributors_count': 0,
            'branches_count': 0,
            'readme_exists': False,
            'has_tests': False,
            'has_ci': False
        }
        
        try:
            # åŸºæœ¬çš„ãªå­˜åœ¨ãƒã‚§ãƒƒã‚¯ã®ã¿ï¼ˆåŠ¹ç‡åŒ–ï¼‰
            contents_response = self.session.get(f'https://api.github.com/repos/{owner}/{repo}/contents')
            if contents_response.status_code == 200:
                contents = contents_response.json()
                file_names = [item['name'].lower() for item in contents if item['type'] == 'file']
                
                # READMEå­˜åœ¨ãƒã‚§ãƒƒã‚¯
                readme_files = ['readme.md', 'readme.rst', 'readme.txt']
                stats['readme_exists'] = any(readme in file_names for readme in readme_files)
                
                # Dockerfileå­˜åœ¨ãƒã‚§ãƒƒã‚¯
                stats['has_ci'] = 'dockerfile' in file_names
                
                # ãƒ†ã‚¹ãƒˆé–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«
                test_indicators = ['test', 'spec', 'tests', '__tests__']
                stats['has_tests'] = any(indicator in name for name in file_names for indicator in test_indicators)
            
            # ã‚³ãƒŸãƒƒãƒˆæ•°ã¯åŸºæœ¬æƒ…å ±ã‹ã‚‰æ¨å®šï¼ˆAPIåŠ¹ç‡åŒ–ï¼‰
            # æ›´æ–°é »åº¦ã‹ã‚‰å¤§ã¾ã‹ã«æ¨å®š
            # ãƒªãƒã‚¸ãƒˆãƒªã‚µã‚¤ã‚ºã‹ã‚‰æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
            repo_size = getattr(self, 'current_repo_size', 100)  # KB
            stats['commit_count'] = max(1, repo_size // 10)  # ã‚µã‚¤ã‚ºã‹ã‚‰å¤§ã¾ã‹ã«æ¨å®š
                    
        except Exception as e:
            print(f"    âš ï¸  çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        return stats

    def get_file_content(self, owner: str, repo: str, path: str) -> Optional[str]:
        """ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ã‚’å–å¾—"""
        try:
            response = self.session.get(f'https://api.github.com/repos/{owner}/{repo}/contents/{path}')
            response.raise_for_status()
            file_data = response.json()
            
            if file_data.get('type') == 'file' and file_data.get('size', 0) < 50000:  # 50KBåˆ¶é™
                import base64
                content = base64.b64decode(file_data['content']).decode('utf-8', errors='ignore')
                return content[:10000]  # æœ€å¤§10000æ–‡å­—
        except:
            pass
        return None
    
    def analyze_repository_tech_stack(self, repo: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒªãƒã‚¸ãƒˆãƒªã®æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã‚’åˆ†æ"""
        try:
            owner = repo['owner']['login']
            name = repo['name']
            
            # åŸºæœ¬æƒ…å ±
            analysis = {
                'name': name,
                'description': repo.get('description', '') or '',
                'primary_language': repo.get('language') or 'Unknown',
                'size': repo.get('size', 0),
                'stars': repo.get('stargazers_count', 0),
                'forks': repo.get('forks_count', 0),
                'created_at': repo.get('created_at', ''),
                'updated_at': repo.get('updated_at', ''),
                'topics': repo.get('topics', []) or [],
                'languages': {},
                'frameworks': [],
                'tools': [],
                'complexity': 'low',
                'category': 'other'
            }
            
            # è¨€èªçµ±è¨ˆå–å¾—
            languages = self.get_repository_languages(owner, name)
            analysis['languages'] = languages
            
            # ãƒªãƒã‚¸ãƒˆãƒªçµ±è¨ˆå–å¾—ï¼ˆåŠ¹ç‡åŒ–ã®ãŸã‚ä¸€éƒ¨ã®ã¿ï¼‰
            self.current_repo_size = analysis['size']  # ã‚µã‚¤ã‚ºã‚’æ¸¡ã™
            stats = self.get_repository_stats(owner, name)
            analysis.update(stats)
            
            # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æï¼ˆåŠ¹ç‡åŒ–ï¼‰
            tech_stack_files = ['package.json', 'requirements.txt', 'go.mod', 'Cargo.toml']
            config_files = ['docker-compose.yml', 'Dockerfile']
            
            # æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯æ¤œå‡ºç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å†…å®¹ã‚’èª­ã¿è¾¼ã¿
            for file_name in tech_stack_files + config_files:
                content = self.get_file_content(owner, name, file_name)
                if content:
                    analysis = self._analyze_file_content(analysis, file_name, content)
            
            # è¤‡é›‘åº¦ã¨ã‚«ãƒ†ã‚´ãƒªã®æ¨å®š
            analysis = self._estimate_complexity_and_category(analysis)
            
            return analysis
        
        except Exception as e:
            print(f"    âš ï¸  {name} ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
            return {
                'name': name,
                'description': '',
                'primary_language': 'Unknown',
                'size': 0,
                'stars': 0,
                'forks': 0,
                'created_at': '',
                'updated_at': '',
                'topics': [],
                'languages': {},
                'frameworks': [],
                'tools': [],
                'complexity': 'low',
                'category': 'other'
            }
    
    def _analyze_file_content(self, analysis: Dict[str, Any], filename: str, content: str) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‹ã‚‰æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã‚’æ¨å®š"""
        
        if filename == 'package.json':
            try:
                pkg_data = json.loads(content)
                deps = list(pkg_data.get('dependencies', {}).keys())
                dev_deps = list(pkg_data.get('devDependencies', {}).keys())
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ¤œå‡º
                frameworks = []
                if any(dep in deps for dep in ['react', '@types/react']):
                    frameworks.append('React')
                if any(dep in deps for dep in ['vue', 'nuxt']):
                    frameworks.append('Vue.js')
                if any(dep in deps for dep in ['angular', '@angular/core']):
                    frameworks.append('Angular')
                if any(dep in deps for dep in ['express', 'koa', 'fastify']):
                    frameworks.append('Node.js Backend')
                if any(dep in deps for dep in ['next', 'gatsby']):
                    frameworks.append('Static Site Generator')
                
                analysis['frameworks'].extend(frameworks)
                analysis['tools'].extend(['npm/yarn'])
                
            except json.JSONDecodeError:
                pass
        
        elif filename == 'requirements.txt':
            lines = content.strip().split('\n')
            frameworks = []
            
            for line in lines:
                package = line.split('==')[0].split('>=')[0].split('~=')[0].strip()
                if package in ['django', 'Django']:
                    frameworks.append('Django')
                elif package in ['flask', 'Flask']:
                    frameworks.append('Flask')
                elif package in ['fastapi', 'FastAPI']:
                    frameworks.append('FastAPI')
                elif package in ['streamlit']:
                    frameworks.append('Streamlit')
                elif package in ['pandas', 'numpy', 'scipy']:
                    frameworks.append('Data Science')
                elif package in ['tensorflow', 'torch', 'pytorch']:
                    frameworks.append('Machine Learning')
            
            analysis['frameworks'].extend(frameworks)
            analysis['tools'].extend(['pip'])
        
        elif filename in ['go.mod']:
            if 'gin-gonic/gin' in content:
                analysis['frameworks'].append('Gin (Go)')
            if 'gorilla/mux' in content:
                analysis['frameworks'].append('Gorilla Mux')
            analysis['tools'].append('Go Modules')
        
        elif filename == 'Cargo.toml':
            if 'actix-web' in content:
                analysis['frameworks'].append('Actix Web')
            if 'rocket' in content:
                analysis['frameworks'].append('Rocket')
            analysis['tools'].append('Cargo')
        
        elif filename == 'Dockerfile':
            analysis['tools'].append('Docker')
        
        elif filename == 'docker-compose.yml':
            analysis['tools'].append('Docker Compose')
        
        return analysis
    
    def _estimate_complexity_and_category(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """è¤‡é›‘åº¦ã¨ã‚«ãƒ†ã‚´ãƒªã‚’æ¨å®š"""
        
        # è¤‡é›‘åº¦æ¨å®š
        complexity_score = 0
        
        # è¨€èªæ•°
        lang_count = len(analysis['languages'])
        complexity_score += min(lang_count * 10, 30)
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ•°
        framework_count = len(analysis['frameworks'])
        complexity_score += min(framework_count * 15, 45)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        size = analysis['size']
        if size > 10000:
            complexity_score += 30
        elif size > 1000:
            complexity_score += 15
        
        # ã‚¹ã‚¿ãƒ¼æ•°ï¼ˆäººæ°—åº¦ï¼‰
        stars = analysis['stars']
        if stars > 100:
            complexity_score += 20
        elif stars > 10:
            complexity_score += 10
        
        if complexity_score >= 60:
            analysis['complexity'] = 'high'
        elif complexity_score >= 30:
            analysis['complexity'] = 'medium'
        else:
            analysis['complexity'] = 'low'
        
        # ã‚«ãƒ†ã‚´ãƒªæ¨å®š
        primary_lang = (analysis['primary_language'] or '').lower()
        frameworks = [f.lower() for f in analysis['frameworks']]
        
        if any(f in frameworks for f in ['react', 'vue.js', 'angular', 'static site generator']):
            analysis['category'] = 'frontend'
        elif any(f in frameworks for f in ['django', 'flask', 'fastapi', 'node.js backend', 'gin (go)', 'actix web']):
            analysis['category'] = 'backend'
        elif any(f in frameworks for f in ['data science', 'machine learning']):
            analysis['category'] = 'data/ml'
        elif 'docker' in analysis['tools']:
            analysis['category'] = 'devops'
        elif primary_lang in ['javascript', 'typescript', 'html', 'css']:
            analysis['category'] = 'frontend'
        elif primary_lang in ['python', 'java', 'go', 'rust', 'c++']:
            analysis['category'] = 'backend'
        else:
            analysis['category'] = 'other'
        
        return analysis
    
    def generate_portfolio_report(self, analyses: List[Dict[str, Any]]) -> str:
        """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        
        # çµ±è¨ˆè¨ˆç®—
        total_repos = len(analyses)
        languages = Counter()
        frameworks = Counter()
        categories = Counter()
        complexities = Counter()
        
        total_stars = 0
        total_forks = 0
        
        for analysis in analyses:
            # è¨€èªçµ±è¨ˆï¼ˆãƒã‚¤ãƒˆæ•°åŠ é‡ï¼‰
            for lang, bytes_count in analysis['languages'].items():
                languages[lang] += bytes_count
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯çµ±è¨ˆ
            for framework in analysis['frameworks']:
                frameworks[framework] += 1
            
            # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆ
            categories[analysis['category']] += 1
            
            # è¤‡é›‘åº¦çµ±è¨ˆ
            complexities[analysis['complexity']] += 1
            
            # ã‚¹ã‚¿ãƒ¼ãƒ»ãƒ•ã‚©ãƒ¼ã‚¯æ•°
            total_stars += analysis['stars']
            total_forks += analysis['forks']
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = f"""
# ğŸš€ GitHub Portfolio Analysis Report
ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š Portfolio Overview
- **ç·ãƒªãƒã‚¸ãƒˆãƒªæ•°**: {total_repos}
- **ç·ã‚¹ã‚¿ãƒ¼æ•°**: {total_stars}
- **ç·ãƒ•ã‚©ãƒ¼ã‚¯æ•°**: {total_forks}
- **å¹³å‡ã‚¹ã‚¿ãƒ¼æ•°**: {total_stars/max(total_repos, 1):.1f}

## ğŸ’» æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯åˆ†æ

### ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª (ä¸Šä½10ä½)
"""
        
        # è¨€èªãƒ©ãƒ³ã‚­ãƒ³ã‚°
        top_languages = languages.most_common(10)
        total_bytes = sum(languages.values())
        
        for i, (lang, bytes_count) in enumerate(top_languages, 1):
            percentage = (bytes_count / max(total_bytes, 1)) * 100
            report += f"{i:2d}. **{lang}**: {percentage:.1f}% ({bytes_count:,} bytes)\n"
        
        report += "\n### ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒª (ä¸Šä½10ä½)\n"
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        top_frameworks = frameworks.most_common(10)
        for i, (framework, count) in enumerate(top_frameworks, 1):
            percentage = (count / max(total_repos, 1)) * 100
            report += f"{i:2d}. **{framework}**: {count} projects ({percentage:.1f}%)\n"
        
        report += f"""
## ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æ

### ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†å¸ƒ
"""
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ
        for category, count in categories.most_common():
            percentage = (count / max(total_repos, 1)) * 100
            report += f"- **{category.title()}**: {count} projects ({percentage:.1f}%)\n"
        
        report += "\n### è¤‡é›‘åº¦åˆ†å¸ƒ\n"
        
        # è¤‡é›‘åº¦åˆ†å¸ƒ
        for complexity, count in complexities.most_common():
            percentage = (count / max(total_repos, 1)) * 100
            report += f"- **{complexity.title()}**: {count} projects ({percentage:.1f}%)\n"
        
        # æ¨å¥¨äº‹é …
        report += self._generate_recommendations(analyses, languages, frameworks, categories)
        
        return report
    
    def _generate_recommendations(self, analyses: List[Dict[str, Any]], 
                                languages: Counter, frameworks: Counter, 
                                categories: Counter) -> str:
        """æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
        
        recommendations = "\n## ğŸ¯ æ¨å¥¨äº‹é …\n\n"
        
        # æŠ€è¡“çš„å¤šæ§˜æ€§ã®åˆ†æ
        lang_diversity = len(languages)
        framework_diversity = len(frameworks)
        
        recommendations += "### æŠ€è¡“ã‚¹ã‚­ãƒ«å‘ä¸Š\n"
        
        # è¨€èªã®æ¨å¥¨
        top_lang = languages.most_common(1)[0][0] if languages else "Unknown"
        
        if lang_diversity < 3:
            recommendations += f"- ç¾åœ¨ã®ãƒ¡ã‚¤ãƒ³è¨€èªã¯ **{top_lang}** ã§ã™ã€‚æŠ€è¡“çš„å¤šæ§˜æ€§å‘ä¸Šã®ãŸã‚ã€ä»¥ä¸‹ã®è¨€èªå­¦ç¿’ã‚’æ¨å¥¨:\n"
            suggestions = []
            if 'Python' not in languages:
                suggestions.append("Pythonï¼ˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼‰")
            if 'JavaScript' not in languages and 'TypeScript' not in languages:
                suggestions.append("JavaScript/TypeScriptï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ»ãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯ï¼‰")
            if 'Go' not in languages:
                suggestions.append("Goï¼ˆé«˜æ€§èƒ½ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼‰")
            
            for suggestion in suggestions[:2]:  # æœ€å¤§2ã¤ã¾ã§
                recommendations += f"  - {suggestion}\n"
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æ¨å¥¨
        if framework_diversity < 5:
            recommendations += "- ãƒ¢ãƒ€ãƒ³ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å­¦ç¿’ã‚’æ¨å¥¨:\n"
            
            frontend_frameworks = [f for f in frameworks if f in ['React', 'Vue.js', 'Angular']]
            if not frontend_frameworks:
                recommendations += "  - **React** ã¾ãŸã¯ **Vue.js** (ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰é–‹ç™º)\n"
            
            backend_frameworks = [f for f in frameworks if f in ['Django', 'Flask', 'FastAPI', 'Express']]
            if not backend_frameworks:
                recommendations += "  - **FastAPI** ã¾ãŸã¯ **Express** (ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰APIé–‹ç™º)\n"
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—ã®æ¨å¥¨
        recommendations += "\n### ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå¼·åŒ–\n"
        
        if categories['frontend'] == 0:
            recommendations += "- **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹é–‹ç™ºã‚¹ã‚­ãƒ«ã®è¨¼æ˜\n"
        
        if categories['backend'] == 0:
            recommendations += "- **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ»API**: ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰é–‹ç™ºã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã‚¹ã‚­ãƒ«ã®è¨¼æ˜\n"
        
        if categories['data/ml'] == 0:
            recommendations += "- **ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»æ©Ÿæ¢°å­¦ç¿’**: ç¾ä»£çš„ãªãƒ‡ãƒ¼ã‚¿æ´»ç”¨ã‚¹ã‚­ãƒ«ã®è¨¼æ˜\n"
        
        if categories['devops'] < 2:
            recommendations += "- **DevOpsãƒ»ã‚¤ãƒ³ãƒ•ãƒ©**: Dockerã€CI/CDã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚¹ã‚­ãƒ«ã®è¨¼æ˜\n"
        
        # å“è³ªå‘ä¸Šã®æ¨å¥¨
        recommendations += "\n### ã‚³ãƒ¼ãƒ‰å“è³ªå‘ä¸Š\n"
        
        low_star_repos = len([a for a in analyses if a['stars'] == 0])
        if low_star_repos > len(analyses) * 0.8:
            recommendations += "- **READMEæ”¹å–„**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç›®çš„ãƒ»ä½¿ç”¨æ–¹æ³•ãƒ»æŠ€è¡“é¸æŠç†ç”±ã‚’æ˜ç¢ºã«è¨˜è¼‰\n"
            recommendations += "- **ãƒ‡ãƒ¢ãƒ»ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ**: å®Ÿéš›ã®å‹•ä½œã‚’è¦–è¦šçš„ã«ç¤ºã™\n"
        
        recommendations += "- **ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰**: å“è³ªä¿è¨¼ã¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒªã‚ºãƒ ã®è¨¼æ˜\n"
        recommendations += "- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: APIä»•æ§˜æ›¸ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³ãªã©ã®æŠ€è¡“æ–‡æ›¸\n"
        
        return recommendations
    
    def generate_human_focused_analysis(self, analyses, user_info):
        """äººã«ç„¦ç‚¹ã‚’å½“ã¦ãŸé–‹ç™ºè€…åˆ†æã‚’ç”Ÿæˆ"""
        
        total_repos = len(analyses)
        total_commits = sum(a.get('commit_count', 0) for a in analyses)
        test_repos = sum(1 for a in analyses if a.get('has_tests', False))
        ci_repos = sum(1 for a in analyses if a.get('has_ci', False))
        readme_repos = sum(1 for a in analyses if a.get('readme_exists', False))
        
        # é–‹ç™ºè€…ã®å‚¾å‘åˆ†æ
        analysis = {
            'working_style': {},
            'collaboration_style': {},
            'technical_habits': {},
            'productivity_patterns': {},
            'quality_consciousness': {}
        }
        
        # === ä½œæ¥­ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æ ===
        avg_commits = total_commits / max(total_repos, 1)
        if avg_commits > 100:
            analysis['working_style']['commitment'] = "é«˜é »åº¦ã‚³ãƒŸãƒƒã‚¿ãƒ¼ - å°ã•ãªå¤‰æ›´ã‚’é »ç¹ã«ã‚³ãƒŸãƒƒãƒˆã™ã‚‹ä¸å¯§ãªä½œæ¥­ã‚¹ã‚¿ã‚¤ãƒ«"
        elif avg_commits > 20:
            analysis['working_style']['commitment'] = "å®‰å®šçš„ã‚³ãƒŸãƒƒã‚¿ãƒ¼ - é©åº¦ãªãƒšãƒ¼ã‚¹ã§ç€å®Ÿã«é–‹ç™ºã‚’é€²ã‚ã‚‹"
        else:
            analysis['working_style']['commitment'] = "ä¸€æ°—é›†ä¸­å‹ - ã¾ã¨ã¾ã£ãŸæ©Ÿèƒ½ã‚’ä¸€åº¦ã«å®Ÿè£…ã™ã‚‹ã‚¿ã‚¤ãƒ—"
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ„è­˜
        readme_rate = readme_repos / max(total_repos, 1)
        if readme_rate > 0.8:
            analysis['working_style']['documentation'] = "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå®Œç’§ä¸»ç¾©è€… - ä»–è€…ã¸ã®é…æ…®ã‚’é‡è¦–ã™ã‚‹ä¸å¯§ãªé–‹ç™ºè€…"
        elif readme_rate > 0.5:
            analysis['working_style']['documentation'] = "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ„è­˜è‰¯å¥½ - ãƒãƒ©ãƒ³ã‚¹æ„Ÿè¦šã®ã‚ã‚‹å®Ÿè·µçš„ãªé–‹ç™ºè€…"
        elif readme_rate > 0.2:
            analysis['working_style']['documentation'] = "ã‚³ãƒ¼ãƒ‰é‡è¦–æ´¾ - å®Ÿè£…ã«é›†ä¸­ã—ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯å¾Œå›ã—ã«ã—ãŒã¡"
        else:
            analysis['working_style']['documentation'] = "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè»½è¦–æ´¾ - ã‚³ãƒ¼ãƒ‰ã§èªã‚‹ã‚¿ã‚¤ãƒ—ï¼ˆè¦æ”¹å–„ï¼‰"
        
        # === ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ã‚¤ãƒ« ===
        # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ã‹ã‚‰åˆ¤æ–­
        followers = user_info.get('followers', 0)
        public_repos = user_info.get('public_repos', 0)
        
        if followers > 50:
            analysis['collaboration_style']['visibility'] = "ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒªãƒ¼ãƒ€ãƒ¼ - å½±éŸ¿åŠ›ã®ã‚ã‚‹ç™ºä¿¡è€…"
        elif followers > 10:
            analysis['collaboration_style']['visibility'] = "ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¡ãƒ³ãƒãƒ¼ - ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ç©æ¥µå‚åŠ "
        else:
            analysis['collaboration_style']['visibility'] = "ã‚µã‚¤ãƒ¬ãƒ³ãƒˆãƒ¯ãƒ¼ã‚«ãƒ¼ - é™ã‹ã«é–‹ç™ºã«å–ã‚Šçµ„ã‚€è·äººæ°—è³ª"
        
        # ãƒªãƒã‚¸ãƒˆãƒªå…¬é–‹ç‡
        if public_repos > 30:
            analysis['collaboration_style']['openness'] = "ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹æ¨é€²æ´¾ - ç©æ¥µçš„ã«ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ãƒ»å…±æœ‰"
        elif public_repos > 10:
            analysis['collaboration_style']['openness'] = "é©åº¦ãªå…¬é–‹æ´¾ - ãƒãƒ©ãƒ³ã‚¹è‰¯ãã‚³ãƒ¼ãƒ‰ã‚’å…±æœ‰"
        else:
            analysis['collaboration_style']['openness'] = "ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆé‡è¦–æ´¾ - æ…é‡ã«ã‚³ãƒ¼ãƒ‰ã‚’ç®¡ç†"
        
        # === æŠ€è¡“ç¿’æ…£ ===
        test_rate = test_repos / max(total_repos, 1)
        if test_rate > 0.7:
            analysis['technical_habits']['testing'] = "ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™ºè€… - å“è³ªç¬¬ä¸€ã®å …å®Ÿãªé–‹ç™ºæ‰‹æ³•"
        elif test_rate > 0.3:
            analysis['technical_habits']['testing'] = "å“è³ªæ„è­˜æ´¾ - é‡è¦ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè£…"
        elif test_rate > 0.1:
            analysis['technical_habits']['testing'] = "ãƒ†ã‚¹ãƒˆå­¦ç¿’ä¸­ - å“è³ªå‘ä¸Šã«å–ã‚Šçµ„ã¿å§‹ã‚ã¦ã„ã‚‹"
        else:
            analysis['technical_habits']['testing'] = "ãƒ†ã‚¹ãƒˆå¾Œå›ã—æ´¾ - ã‚¹ãƒ”ãƒ¼ãƒ‰é‡è¦–ã€å“è³ªã¯é‹ç”¨ã§è§£æ±ºã—ãŒã¡"
        
        ci_rate = ci_repos / max(total_repos, 1)
        if ci_rate > 0.5:
            analysis['technical_habits']['automation'] = "è‡ªå‹•åŒ–ãƒã‚¹ã‚¿ãƒ¼ - åŠ¹ç‡çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰"
        elif ci_rate > 0.2:
            analysis['technical_habits']['automation'] = "è‡ªå‹•åŒ–å°å…¥ä¸­ - ãƒ¢ãƒ€ãƒ³ãªé–‹ç™ºæ‰‹æ³•ã‚’å­¦ç¿’ãƒ»å®Ÿè·µ"
        else:
            analysis['technical_habits']['automation'] = "æ‰‹å‹•æ´¾ - å¾“æ¥å‹ã®é–‹ç™ºã‚¹ã‚¿ã‚¤ãƒ«ã‚’ç¶­æŒ"
        
        # === æˆé•·ãƒ‘ã‚¿ãƒ¼ãƒ³ ===
        recent_activity = len([a for a in analyses if self._is_recent_project(a)])
        if recent_activity / max(total_repos, 1) > 0.6:
            analysis['productivity_patterns']['activity'] = "ç¾åœ¨é€²è¡Œå½¢ - æ´»ç™ºã«æ–°ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å–ã‚Šçµ„ã‚“ã§ã„ã‚‹"
        elif recent_activity > 0:
            analysis['productivity_patterns']['activity'] = "é¸æŠçš„ã‚¢ã‚¯ãƒ†ã‚£ãƒ– - å³é¸ã—ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«é›†ä¸­"
        else:
            analysis['productivity_patterns']['activity'] = "éå»ã®éºç”£ - ç¾åœ¨ã¯ã‚ã¾ã‚Šã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã§ãªã„å¯èƒ½æ€§"
        
        # === å•é¡Œè§£æ±ºã‚¹ã‚¿ã‚¤ãƒ« ===
        complexity_high = len([a for a in analyses if a.get('complexity') == 'high'])
        if complexity_high / max(total_repos, 1) > 0.4:
            analysis['technical_habits']['complexity'] = "è¤‡é›‘æ€§æŒ‘æˆ¦è€… - é›£ã—ã„å•é¡Œã«ç©æ¥µçš„ã«å–ã‚Šçµ„ã‚€"
        elif complexity_high > 0:
            analysis['technical_habits']['complexity'] = "ãƒãƒ©ãƒ³ã‚¹å¿—å‘ - é©åº¦ãªé›£æ˜“åº¦ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é¸æŠ"
        else:
            analysis['technical_habits']['complexity'] = "ã‚·ãƒ³ãƒ—ãƒ«æŒ‡å‘ - åˆ†ã‹ã‚Šã‚„ã™ãå®Ÿç”¨çš„ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é‡è¦–"
        
        return analysis
    
    def _is_recent_project(self, analysis: Dict[str, Any]) -> bool:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒæœ€è¿‘ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‹ã©ã†ã‹åˆ¤å®š"""
        try:
            if analysis.get('updated_at'):
                updated = datetime.fromisoformat(analysis['updated_at'].replace('Z', '+00:00'))
                return updated > datetime.now().replace(tzinfo=updated.tzinfo) - timedelta(days=180)
        except:
            pass
        return False
    
    def save_detailed_analysis(self, analyses: List[Dict[str, Any]], filename: str = 'portfolio_analysis.json'):
        """è©³ç´°åˆ†æçµæœã‚’JSONã§ä¿å­˜"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(analyses, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ è©³ç´°åˆ†æçµæœã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    def generate_claude_analysis_prompt(self, analyses: List[Dict[str, Any]], user_info: Dict[str, Any]) -> str:
        """Claude Codeç”¨ã®è©³ç´°åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
        
        # çµ±è¨ˆè¨ˆç®—
        total_repos = len(analyses)
        languages = Counter()
        frameworks = Counter()
        categories = Counter()
        tools = Counter()
        
        total_commits = 0
        test_coverage = 0
        ci_usage = 0
        
        for analysis in analyses:
            # è¨€èªçµ±è¨ˆ
            for lang, bytes_count in analysis['languages'].items():
                languages[lang] += bytes_count
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ»ãƒ„ãƒ¼ãƒ«çµ±è¨ˆ
            for framework in analysis['frameworks']:
                frameworks[framework] += 1
            for tool in analysis['tools']:
                tools[tool] += 1
            
            # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆ
            categories[analysis['category']] += 1
            
            # çµ±è¨ˆå€¤è“„ç©
            total_commits += analysis.get('commit_count', 0)
            if analysis.get('has_tests', False):
                test_coverage += 1
            if analysis.get('has_ci', False):
                ci_usage += 1
        
        # äººé–“é‡è¦–ã®åˆ†æç”Ÿæˆ
        human_analysis = self.generate_human_focused_analysis(analyses, user_info)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        prompt = f"""# GitHub Portfolio æ·±å±¤åˆ†æä¾é ¼

## ğŸ‘¤ é–‹ç™ºè€…ã®äººé–“æ€§åˆ†æ

### ä½œæ¥­ã‚¹ã‚¿ã‚¤ãƒ«
- **ã‚³ãƒŸãƒƒãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³**: {human_analysis['working_style']['commitment']}
- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ„è­˜**: {human_analysis['working_style']['documentation']}

### ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ã‚¤ãƒ«  
- **ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã§ã®å­˜åœ¨æ„Ÿ**: {human_analysis['collaboration_style']['visibility']}
- **ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å§¿å‹¢**: {human_analysis['collaboration_style']['openness']}

### æŠ€è¡“ç¿’æ…£
- **ãƒ†ã‚¹ãƒˆãƒ»å“è³ªã¸ã®å–ã‚Šçµ„ã¿**: {human_analysis['technical_habits']['testing']}
- **è‡ªå‹•åŒ–ãƒ»åŠ¹ç‡åŒ–ã¸ã®å§¿å‹¢**: {human_analysis['technical_habits']['automation']}
- **è¤‡é›‘æ€§ã¸ã®å¯¾å¿œ**: {human_analysis['technical_habits']['complexity']}

### é–‹ç™ºæ´»å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³
- **ç¾åœ¨ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£**: {human_analysis['productivity_patterns']['activity']}

### æ•°å€¤ã‚µãƒãƒªãƒ¼
- **ç·ã‚³ãƒŸãƒƒãƒˆæ•°**: {total_commits:,}
- **å¹³å‡ã‚³ãƒŸãƒƒãƒˆæ•°/repo**: {total_commits/max(total_repos, 1):.1f}
- **ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸**: {test_coverage}/{total_repos} repos ({test_coverage/max(total_repos, 1)*100:.1f}%)
- **CI/CDå°å…¥ç‡**: {ci_usage}/{total_repos} repos ({ci_usage/max(total_repos, 1)*100:.1f}%)
- **READMEã‚«ãƒãƒ¬ãƒƒã‚¸**: {len([a for a in analyses if a.get('readme_exists', False)])}/{total_repos} repos ({len([a for a in analyses if a.get('readme_exists', False)])/max(total_repos, 1)*100:.1f}%)

---

ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ†ãƒƒã‚¯ãƒªãƒ¼ãƒ‰ã‹ã¤ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®GitHubãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ‡ãƒ¼ã‚¿ã‚’è©³ç´°ã«åˆ†æã—ã€æŠ€è¡“çš„è©•ä¾¡ã¨ã‚­ãƒ£ãƒªã‚¢æˆ¦ç•¥ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

## ğŸ“Š åŸºæœ¬æƒ…å ±
- **GitHub ãƒ¦ãƒ¼ã‚¶ãƒ¼å**: {user_info.get('login', 'N/A')}
- **å…¬é–‹ãƒªãƒã‚¸ãƒˆãƒªæ•°**: {user_info.get('public_repos', 'N/A')}
- **ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°**: {user_info.get('followers', 'N/A')}
- **åˆ†æå¯¾è±¡ãƒªãƒã‚¸ãƒˆãƒª**: {total_repos}

## ğŸ’» æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯è©³ç´°

### ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªåˆ†å¸ƒ
```json
{json.dumps(dict(languages.most_common()), ensure_ascii=False, indent=2)}
```

### ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨çŠ¶æ³
```json
{json.dumps(dict(frameworks.most_common()), ensure_ascii=False, indent=2)}
```

### é–‹ç™ºãƒ„ãƒ¼ãƒ«ãƒ»æŠ€è¡“
```json
{json.dumps(dict(tools.most_common()), ensure_ascii=False, indent=2)}
```

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ
```json
{json.dumps(dict(categories.most_common()), ensure_ascii=False, indent=2)}
```

## ğŸ¯ é–‹ç™ºè€…èƒ½åŠ›åˆ†æ

### å¾—æ„åˆ†é‡ãƒ»å°‚é–€æ€§
ã“ã®é–‹ç™ºè€…ã®æŠ€è¡“çš„ãªå¼·ã¿ã¨å°‚é–€åˆ†é‡ã‚’æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã‹ã‚‰åˆ†æï¼š

**è¨€èªçš„å°‚é–€æ€§:**
{chr(10).join(f"- **{lang}**: {(bytes_count/sum(languages.values())*100):.1f}%ã®ä½¿ç”¨ç‡" for lang, bytes_count in languages.most_common(3))}

**æŠ€è¡“é ˜åŸŸã®å‚¾å‘:**
- **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å¿—å‘**: {categories.get('frontend', 0)}/{total_repos} projects ({categories.get('frontend', 0)/max(total_repos, 1)*100:.1f}%)
- **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å¿—å‘**: {categories.get('backend', 0)}/{total_repos} projects ({categories.get('backend', 0)/max(total_repos, 1)*100:.1f}%)
- **ãƒ‡ãƒ¼ã‚¿ãƒ»MLå¿—å‘**: {categories.get('data/ml', 0)}/{total_repos} projects ({categories.get('data/ml', 0)/max(total_repos, 1)*100:.1f}%)
- **DevOpså¿—å‘**: {categories.get('devops', 0)}/{total_repos} projects ({categories.get('devops', 0)/max(total_repos, 1)*100:.1f}%)

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå“è³ªå‚¾å‘
ã“ã®é–‹ç™ºè€…ã®é–‹ç™ºå“è³ªãƒ»ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒªã‚ºãƒ ã®æŒ‡æ¨™ï¼š

**å“è³ªç®¡ç†ã®å–ã‚Šçµ„ã¿:**
- **ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ç‡**: {test_coverage}/{total_repos} repos ({test_coverage/max(total_repos, 1)*100:.1f}%) 
- **CI/CDå°å…¥ç‡**: {ci_usage}/{total_repos} repos ({ci_usage/max(total_repos, 1)*100:.1f}%)
- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´å‚™ç‡**: {len([a for a in analyses if a.get('readme_exists', False)])}/{total_repos} repos ({len([a for a in analyses if a.get('readme_exists', False)])/max(total_repos, 1)*100:.1f}%)

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã‚¹ã‚¿ã‚¤ãƒ«:**
- **å¹³å‡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¤‡é›‘åº¦**: {sum(1 for a in analyses if a.get('complexity') == 'high')}/{total_repos} high-complexity projects
- **æŠ€è¡“å¤šæ§˜æ€§**: {len(languages)} programming languages across projects
- **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ´»ç”¨åº¦**: {len(frameworks)} different frameworks/libraries used

## ğŸ“‹ åˆ†æä¾é ¼å†…å®¹

ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è©³ç´°ã«åˆ†æãƒ»è©•ä¾¡ã—ã¦ãã ã•ã„ï¼š

### 0. é–‹ç™ºè€…ç§°å·ã®å‘½å ğŸ†
ä¸Šè¨˜ã®äººé–“æ€§åˆ†æã¨æŠ€è¡“ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã€ã“ã®é–‹ç™ºè€…ã«ãµã•ã‚ã—ã„**ã‚­ãƒ£ãƒƒãƒãƒ¼ã§é¢ç™½ã„ç§°å·**ã‚’è€ƒæ¡ˆã—ã¦ãã ã•ã„ï¼š

**ç§°å·ã®ä¾‹ï¼ˆãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒƒã‚¯ãƒ»RPGé¢¨ã‚‚æ­“è¿ï¼‰:**
- ğŸ›¡ï¸ TypeScript Guardianï¼ˆå‹å®‰å…¨ã®å®ˆè­·è€…ï¼‰
- ğŸ§™â€â™‚ï¸ Code Wizardï¼ˆã‚³ãƒ¼ãƒ‰é­”æ³•ä½¿ã„ï¼‰
- âš”ï¸ Bug Slayerï¼ˆãƒã‚°è¨ä¼è€…ï¼‰
- ğŸ° Architecture Architectï¼ˆè¨­è¨ˆå»ºç¯‰å®¶ï¼‰
- ğŸ“œ Documentation Sageï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè³¢è€…ï¼‰
- âš¡ Lightning Coderï¼ˆç¨²å¦»ã‚³ãƒ¼ãƒ€ãƒ¼ï¼‰
- ğŸŒŸ Framework Summonerï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å¬å–šå¸«ï¼‰
- ğŸ—¡ï¸ Legacy Code Warriorï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ã‚³ãƒ¼ãƒ‰æˆ¦å£«ï¼‰
- ğŸ¯ Feature Sniperï¼ˆæ©Ÿèƒ½ç‹™æ’ƒæ‰‹ï¼‰
- ğŸ”® API Alchemistï¼ˆAPIéŒ¬é‡‘è¡“å¸«ï¼‰
- ğŸ› ï¸ DevOps Paladinï¼ˆDevOpsè–é¨å£«ï¼‰
- ğŸ‰ Performance Dragon Tamerï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç«œä½¿ã„ï¼‰
- ğŸ­ Frontend Performerï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰èŠ¸äººï¼‰
- ğŸ”ï¸ Backend Mountain Builderï¼ˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å±±ç¯‰å¸«ï¼‰

**ä¸åèª‰ç§°å·ã‚‚å«ã‚ã¦ï¼ˆæ”¹å–„ç‚¹ã¨ã—ã¦ï¼‰:**
- ğŸ“ README Hermitï¼ˆèª¬æ˜æ›¸éš è€…ï¼‰
- ğŸ§ª Test Phobicï¼ˆãƒ†ã‚¹ãƒˆææ€–ç—‡ï¼‰
- ğŸ’¾ Commit Hoarderï¼ˆã‚³ãƒŸãƒƒãƒˆè²¯è”µç™–ï¼‰
- ğŸ”’ Solo Adventurerï¼ˆä¸€äººå†’é™ºè€…ï¼‰
- ğŸ› Bug Breederï¼ˆãƒã‚°é¤Šæ®–å®¶ï¼‰
- ğŸ“Š Issue Collectorï¼ˆèª²é¡Œã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ï¼‰

**è¦æ±‚:** ç§°å·ã¯å¿…ãšçµµæ–‡å­—ä»˜ãã§ã€ãã®äººã®ç‰¹å¾´ã‚’çš„ç¢ºã«è¡¨ç¾ã—ã€å°‘ã—é¢ç™½ã¿ã®ã‚ã‚‹ã‚‚ã®ã«ã—ã¦ãã ã•ã„ã€‚

### 1. æŠ€è¡“çš„ã‚¹ã‚­ãƒ«è©•ä¾¡ (å„é …ç›®10ç‚¹æº€ç‚¹)
- **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰æŠ€è¡“åŠ›**
- **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æŠ€è¡“åŠ›**
- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ»ãƒ‡ãƒ¼ã‚¿å‡¦ç†**
- **DevOpsãƒ»ã‚¤ãƒ³ãƒ•ãƒ©**
- **ãƒ¢ãƒã‚¤ãƒ«é–‹ç™º**
- **AI/MLæŠ€è¡“**
- **æŠ€è¡“ã®å¤šæ§˜æ€§ã¨æ·±åº¦**
- **ãƒ¢ãƒ€ãƒ³ãªæŠ€è¡“ã¸ã®é©å¿œ**

### 2. ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å“è³ªè©•ä¾¡
- **ã‚³ãƒ¼ãƒ‰è¨­è¨ˆãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆãƒ»ç®¡ç†**
- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»READMEå“è³ª**
- **ãƒ†ã‚¹ãƒˆãƒ»å“è³ªä¿è¨¼ã¸ã®å–ã‚Šçµ„ã¿**
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ„è­˜**
- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**

### 3. ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒ»ãƒ“ã‚¸ãƒã‚¹è¦–ç‚¹
- **å®Ÿç”¨æ€§ãƒ»å¸‚å ´ä¾¡å€¤**
- **UI/UXè¨­è¨ˆåŠ›**
- **å•é¡Œè§£æ±ºã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**
- **ç¶™ç¶šçš„ãªé–‹ç™ºãƒ»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹**
- **ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹è²¢çŒ®**

### 4. ã‚­ãƒ£ãƒªã‚¢æˆ¦ç•¥ææ¡ˆ
- **ç¾åœ¨ã®å¸‚å ´ä¾¡å€¤(å¹´åãƒ¬ãƒ³ã‚¸äºˆæƒ³)**
- **å¼·ã¿ã¨å¼±ã¿ã®æ˜ç¢ºåŒ–**
- **æ¬¡ã«ç¿’å¾—ã™ã¹ãæŠ€è¡“(å„ªå…ˆåº¦é †)**
- **ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ”¹å–„é …ç›®(å…·ä½“çš„)**
- **è»¢è·ãƒ»ã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒƒãƒ—æˆ¦ç•¥**
- **å­¦ç¿’è¨ˆç”»(6ãƒ¶æœˆãƒ»1å¹´ãƒ»3å¹´)**

### 5. å…·ä½“çš„æ”¹å–„ææ¡ˆ
- **ä¸è¶³ã—ã¦ã„ã‚‹æŠ€è¡“é ˜åŸŸ**
- **ä½œã‚‹ã¹ããƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ(3-5å€‹)**
- **æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ”¹å–„ç‚¹**
- **æŠ€è¡“ãƒ–ãƒ­ã‚°ãƒ»ç™ºä¿¡ã™ã¹ãå†…å®¹**
- **å‚åŠ ã™ã¹ãã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆ**

## ğŸ“ å‡ºåŠ›å½¢å¼
- å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯è©³ç´°ã‹ã¤å…·ä½“çš„ã«
- ã‚¹ã‚³ã‚¢ã¯æ ¹æ‹ ã¨ã¨ã‚‚ã«æç¤º
- æ”¹å–„ææ¡ˆã¯å®Ÿè¡Œå¯èƒ½ãªå…·ä½“æ¡ˆã‚’
- å¸‚å ´å‹•å‘ã¨ç…§ã‚‰ã—åˆã‚ã›ãŸåˆ†æã‚’
- ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®ãƒ¬ãƒ™ãƒ«æ„Ÿã‚’è€ƒæ…®ã—ãŸç¾å®Ÿçš„ãªææ¡ˆã‚’

ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ï¼"""

        return prompt
    
    def generate_developer_card_html(self, analyses: List[Dict[str, Any]], user_info: Dict[str, Any], languages: Counter, frameworks: Counter) -> str:
        """é–‹ç™ºè€…ã‚«ãƒ¼ãƒ‰ç”¨ã®HTMLã‚’ç”Ÿæˆ"""
        
        human_analysis = self.generate_human_focused_analysis(analyses, user_info)
        total_commits = sum(a.get('commit_count', 0) for a in analyses)
        test_coverage = sum(1 for a in analyses if a.get('has_tests', False))
        ci_usage = sum(1 for a in analyses if a.get('has_ci', False))
        readme_coverage = sum(1 for a in analyses if a.get('readme_exists', False))
        
        # ãƒˆãƒƒãƒ—3è¨€èª
        top_languages = languages.most_common(3)
        total_bytes = sum(languages.values())
        
        # ãƒˆãƒƒãƒ—ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
        top_frameworks = frameworks.most_common(3)
        
        html = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Developer Card - {user_info.get('login', 'Unknown')}</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap');
        
        body {{
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            font-family: 'Inter', sans-serif;
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
        }}
        
        .developer-card {{
            background: white;
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.15);
            max-width: 450px;
            width: 100%;
            position: relative;
            overflow: hidden;
        }}
        
        .developer-card::before {{
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 8px;
            background: linear-gradient(90deg, #ff6b6b, #4ecdc4, #45b7d1, #96ceb4, #ffeaa7);
        }}
        
        .header {{
            text-align: center;
            margin-bottom: 25px;
        }}
        
        .username {{
            font-size: 28px;
            font-weight: 700;
            margin: 10px 0 5px 0;
            color: #2d3436;
        }}
        
        .subtitle {{
            color: #636e72;
            font-size: 14px;
            margin-bottom: 15px;
        }}
        
        .title-section {{
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            padding: 15px;
            border-radius: 12px;
            margin-bottom: 20px;
            text-align: center;
        }}
        
        .title {{
            font-size: 18px;
            font-weight: 600;
            margin: 0;
        }}
        
        .stats-grid {{
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
            margin-bottom: 20px;
        }}
        
        .stat-item {{
            background: #f8f9fa;
            padding: 12px;
            border-radius: 8px;
            text-align: center;
        }}
        
        .stat-number {{
            font-size: 20px;
            font-weight: 700;
            color: #2d3436;
            display: block;
        }}
        
        .stat-label {{
            font-size: 11px;
            color: #636e72;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }}
        
        .skills-section {{
            margin-bottom: 20px;
        }}
        
        .section-title {{
            font-size: 14px;
            font-weight: 600;
            color: #2d3436;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 8px;
        }}
        
        .skill-bar {{
            margin-bottom: 8px;
        }}
        
        .skill-name {{
            font-size: 12px;
            color: #636e72;
            margin-bottom: 4px;
            display: flex;
            justify-content: space-between;
        }}
        
        .progress-bar {{
            height: 6px;
            background: #e9ecef;
            border-radius: 3px;
            overflow: hidden;
        }}
        
        .progress-fill {{
            height: 100%;
            background: linear-gradient(90deg, #667eea, #764ba2);
            transition: width 0.3s ease;
        }}
        
        .traits {{
            margin-bottom: 20px;
        }}
        
        .trait-item {{
            background: #e8f5e8;
            color: #2d5a2d;
            padding: 6px 12px;
            border-radius: 15px;
            font-size: 11px;
            margin: 5px 5px 0 0;
            display: inline-block;
        }}
        
        .generated-info {{
            text-align: center;
            color: #636e72;
            font-size: 10px;
            margin-top: 20px;
            padding-top: 15px;
            border-top: 1px solid #e9ecef;
        }}
    </style>
</head>
<body>
    <div class="developer-card">
        <div class="header">
            <div class="username">{user_info.get('login', 'Unknown')}</div>
            <div class="subtitle">GitHub Portfolio Analysis</div>
        </div>
        
        <div class="title-section">
            <div class="title">ğŸ­ ç§°å·ã¯Claude Codeã§æ±ºå®šã—ã¦ã‚‚ã‚‰ã£ã¦ãã ã•ã„</div>
        </div>
        
        <div class="stats-grid">
            <div class="stat-item">
                <span class="stat-number">{len(analyses)}</span>
                <span class="stat-label">Projects</span>
            </div>
            <div class="stat-item">
                <span class="stat-number">{total_commits:,}</span>
                <span class="stat-label">Commits</span>
            </div>
            <div class="stat-item">
                <span class="stat-number">{test_coverage}/{len(analyses)}</span>
                <span class="stat-label">Test Coverage</span>
            </div>
            <div class="stat-item">
                <span class="stat-number">{readme_coverage}/{len(analyses)}</span>
                <span class="stat-label">Documentation</span>
            </div>
        </div>
        
        <div class="skills-section">
            <div class="section-title">ğŸ’» Top Languages</div>
            {chr(10).join(f'''
            <div class="skill-bar">
                <div class="skill-name">
                    <span>{lang}</span>
                    <span>{(bytes_count/max(total_bytes, 1)*100):.1f}%</span>
                </div>
                <div class="progress-bar">
                    <div class="progress-fill" style="width: {(bytes_count/max(total_bytes, 1)*100):.1f}%"></div>
                </div>
            </div>''' for lang, bytes_count in top_languages)}
        </div>
        
        <div class="skills-section">
            <div class="section-title">ğŸ› ï¸ Frameworks</div>
            {chr(10).join(f'<div class="trait-item">{framework} ({count})</div>' for framework, count in top_frameworks)}
        </div>
        
        <div class="traits">
            <div class="section-title">ğŸ·ï¸ Developer Traits</div>
            <div class="trait-item">{human_analysis['working_style']['commitment'].split(' - ')[0]}</div>
            <div class="trait-item">{human_analysis['working_style']['documentation'].split(' - ')[0]}</div>
            <div class="trait-item">{human_analysis['collaboration_style']['visibility'].split(' - ')[0]}</div>
        </div>
        
        <div class="generated-info">
            Generated on {datetime.now().strftime('%Y-%m-%d %H:%M')} â€¢ GitHub Portfolio Analyzer
        </div>
    </div>
</body>
</html>"""
        
        return html


def main():
    parser = argparse.ArgumentParser(description='GitHub Portfolio Analyzer')
    parser.add_argument('--token', help='GitHub Personal Access Token')
    parser.add_argument('--max-repos', type=int, default=100, help='åˆ†æã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒªã®æœ€å¤§æ•°')
    parser.add_argument('--output', default='report.md', help='ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å')
    parser.add_argument('--save-json', action='store_true', help='è©³ç´°åˆ†æçµæœã‚’JSONã§ä¿å­˜')
    
    args = parser.parse_args()
    
    # .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    load_env_file()
    
    # GitHub Tokenå–å¾—
    token = args.token or os.getenv('GITHUB_TOKEN')
    if not token:
        print("âŒ GitHub Personal Access TokenãŒå¿…è¦ã§ã™")
        print("   --token ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¾ãŸã¯ GITHUB_TOKEN ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        sys.exit(1)
    
    try:
        analyzer = GitHubAnalyzer(token)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å–å¾—
        user_info = analyzer.get_user_info()
        print(f"ğŸ” {user_info['login']} ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’åˆ†æä¸­...")
        
        # ãƒªãƒã‚¸ãƒˆãƒªå–å¾—
        repos = analyzer.get_all_repositories(args.max_repos)
        print(f"ğŸ“¦ {len(repos)} å€‹ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—ã—ã¾ã—ãŸ")
        
        # å„ãƒªãƒã‚¸ãƒˆãƒªã‚’åˆ†æ
        analyses = []
        for i, repo in enumerate(repos, 1):
            print(f"ğŸ” [{i:3d}/{len(repos):3d}] {repo['name']} ã‚’åˆ†æä¸­...")
            analysis = analyzer.analyze_repository_tech_stack(repo)
            analyses.append(analysis)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print("ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
        report = analyzer.generate_portfolio_report(analyses)
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ… åˆ†æå®Œäº†ï¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ {args.output} ã«ä¿å­˜ã—ã¾ã—ãŸ")
        
        # è©³ç´°åˆ†æçµæœã‚’JSONã§ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if args.save_json:
            analyzer.save_detailed_analysis(analyses)
        
        # Claude Codeç”¨ã®è©³ç´°åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
        claude_prompt = analyzer.generate_claude_analysis_prompt(analyses, user_info)
        claude_prompt_file = 'claude_analysis_prompt.md'
        with open(claude_prompt_file, 'w', encoding='utf-8') as f:
            f.write(claude_prompt)
        
        # é–‹ç™ºè€…ã‚«ãƒ¼ãƒ‰HTMLç”Ÿæˆ
        languages = Counter()
        frameworks = Counter()
        for analysis in analyses:
            for lang, bytes_count in analysis['languages'].items():
                languages[lang] += bytes_count
            for framework in analysis['frameworks']:
                frameworks[framework] += 1
        
        card_html = analyzer.generate_developer_card_html(analyses, user_info, languages, frameworks)
        card_file = 'developer_card.html'
        with open(card_file, 'w', encoding='utf-8') as f:
            f.write(card_html)
        
        print(f"ğŸ¤– Claude Codeåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ {claude_prompt_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")
        print(f"ğŸ¨ é–‹ç™ºè€…ã‚«ãƒ¼ãƒ‰HTMLã‚’ {card_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")
        print("\n" + "="*80)
        print("ğŸ“‹ æ¬¡ã®æ‰‹é †:")
        print("1. Claude Codeã§ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
        print("2. è©³ç´°ãªæŠ€è¡“åˆ†æã¨ã‚­ãƒ£ãƒªã‚¢ææ¡ˆã‚’å—ã‘å–ã‚Œã¾ã™")
        print(f"3. {card_file} ã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ãã¨ç¾ã—ã„ã‚«ãƒ¼ãƒ‰ãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
        print("="*80)
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ GitHub API ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()